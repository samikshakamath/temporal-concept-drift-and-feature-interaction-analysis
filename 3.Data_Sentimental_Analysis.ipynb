{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bf102122-6ce0-45af-be38-c1d679faaddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111611b0-c359-4931-88c6-c573134eab63",
   "metadata": {},
   "source": [
    "# Load Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d4301b6-6d35-4afe-9d96-b47bbb48e6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "British Airways shape: (3218, 29)\n",
      "Emirates shape: (1475, 29)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load Excel datasets\n",
    "# ----------------------------\n",
    "ba_path = r\"C:\\Users\\Samiksha\\Downloads\\BA_updated.xlsx\"\n",
    "emirates_path = r\"C:\\Users\\Samiksha\\Downloads\\Emirates_updated.xlsx\"\n",
    "\n",
    "ba_df = pd.read_excel(ba_path)\n",
    "emirates_df = pd.read_excel(emirates_path)\n",
    "\n",
    "print(\"British Airways shape:\", ba_df.shape)\n",
    "print(\"Emirates shape:\", emirates_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025eaf2c-679c-4dea-95f7-9e14ae729757",
   "metadata": {},
   "source": [
    "# torch / torchvision / torchaudio → PyTorch’s deep learning framework plus its vision and audio toolkits.\n",
    "# transformers → Hugging Face’s library for using and fine-tuning state-of-the-art pretrained AI models for text, images, and audio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f54caaf0-b2f5-4377-a53f-37ba7d9dfc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88a572fa-566a-4b00-bb7e-31718fa98d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (4.55.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from transformers) (0.34.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from transformers) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from transformers) (0.6.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\samiksha\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8d17d8-5c3d-4b7a-b80e-d04d8823194b",
   "metadata": {},
   "source": [
    "#  Loads a pretrained Twitter-specific RoBERTa sentiment model and tokenizer, ready to process text and output sentiment probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d30f2aad-f9d4-404e-92d7-e6ab21f2d1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL = \"cardiffnlp/twitter-roberta-base-sentiment\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "041fbd2d-0f52-4a5b-b511-9bd8f3144aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\n+', ' ', text)                  # remove newlines\n",
    "    text = re.sub(r'http\\S+', '', text)               # remove links\n",
    "    text = re.sub(r'[^a-z0-9\\s\\.\\,\\!\\?\\'\\\"]+', '', text)  # keep only basic chars\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6b9fe3-a70c-4a3e-ab37-3bc43b443492",
   "metadata": {},
   "source": [
    "### Text Cleaning and Sentiment Scoring with RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38802cd8-1d8f-4d2c-b1ac-53ed1879084e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_roberta(text):\n",
    "    if not text or text.strip() == \"\":  # empty after cleaning\n",
    "        return pd.Series({\n",
    "            'sentiment_label': \"missing\",\n",
    "            'sentiment_confidence': None,\n",
    "            'score_neg': None,\n",
    "            'score_neu': None,\n",
    "            'score_pos': None\n",
    "        })\n",
    "    try:\n",
    "        encoded_input = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "        with torch.no_grad():\n",
    "            output = model(**encoded_input)\n",
    "\n",
    "        scores = softmax(output.logits.numpy()[0])\n",
    "        labels = ['negative', 'neutral', 'positive']\n",
    "\n",
    "        return pd.Series({\n",
    "            'sentiment_label': labels[scores.argmax()],\n",
    "            'sentiment_confidence': float(scores.max()),\n",
    "            'score_neg': float(scores[0]),\n",
    "            'score_neu': float(scores[1]),\n",
    "            'score_pos': float(scores[2])\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing: {text[:100]}... | {e}\")\n",
    "        return pd.Series({\n",
    "            'sentiment_label': \"error\",\n",
    "            'sentiment_confidence': None,\n",
    "            'score_neg': None,\n",
    "            'score_neu': None,\n",
    "            'score_pos': None\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68600f1f-89cd-44eb-a89e-c403a2249362",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3218/3218 [00:00<00:00, 10143.57it/s]\n",
      "100%|██████████| 3218/3218 [17:14<00:00,  3.11it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "ba_df['review_text_clean'] = ba_df['review_text'].progress_apply(clean_review_text)\n",
    "\n",
    "sentiments = ba_df['review_text_clean'].progress_apply(get_sentiment_roberta)\n",
    "\n",
    "# Merge results back\n",
    "ba_df = pd.concat([ba_df, sentiments], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b0a968f5-ea31-4377-812b-c948bfa37034",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1475/1475 [00:00<00:00, 8558.17it/s]\n",
      "100%|██████████| 1475/1475 [07:31<00:00,  3.27it/s]\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "# Clean review text\n",
    "emirates_df['review_text_clean'] = emirates_df['review_text'].progress_apply(clean_review_text)\n",
    "\n",
    "# Run sentiment scoring\n",
    "sentiments_em = emirates_df['review_text_clean'].progress_apply(get_sentiment_roberta)\n",
    "\n",
    "# Merge results back\n",
    "emirates_df = pd.concat([emirates_df, sentiments_em], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e59373c-3f65-4201-9096-104a72d3c5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing/error sentiments: 0 out of 1475\n"
     ]
    }
   ],
   "source": [
    "missing_count = emirates_df['sentiment_label'].isin([\"missing\", \"error\"]).sum()\n",
    "print(f\"Missing/error sentiments: {missing_count} out of {len(emirates_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7499f556-fb9e-4346-9342-6d9e2bd995e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ba_df.to_csv(r\"C:\\Users\\Samiksha\\Downloads\\2BA_with_sentiment.csv\", index=False)\n",
    "emirates_df.to_csv(r\"C:\\Users\\Samiksha\\Downloads\\2Em_with_sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff21df7-ccbe-4113-a7c2-cc137857b216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Sentiment scores added and files saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the updated dataframes\n",
    "emirates_df.to_csv(r\"C:\\Users\\Samiksha\\Documents\\Dissertataion python\\Anu_ba1_Updated_with_sentiment.csv\", index=False)\n",
    "ba_df.to_csv(r\"C:\\Users\\Samiksha\\Documents\\Dissertataion python\\Anu_em1_updated_with_sentiment.csv\", index=False)\n",
    "\n",
    "print(\"\\n Sentiment scores added and files saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
